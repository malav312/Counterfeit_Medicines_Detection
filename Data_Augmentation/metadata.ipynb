{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "from google.cloud import vision\n",
    "import io\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from difflib import SequenceMatcher\n",
    "from textblob import TextBlob\n",
    "from fuzzywuzzy import process, fuzz\n",
    "import re\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pytesseract\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Stop Words\n",
    "stop = stopwords.words('english')\n",
    "with open('selected_words.txt', 'r') as f:\n",
    "    stop_words = [word.strip().replace('\"', '') for line in f.readlines() for word in line.split(',')]\n",
    "stop.extend(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detect and Process Text here\n",
    "def lower_case(df):\n",
    "    df['text'] = df['text'].apply(str.lower)\n",
    "    return df\n",
    "\n",
    "def remove_punctuations(df):\n",
    "    cleaned_text = []\n",
    "    for index in tqdm(range(df.shape[0])):\n",
    "        text = df['text'].iloc[index]\n",
    "\n",
    "        word_tokens = text.split()\n",
    "        \n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        stripped = [w.translate(table) for w in word_tokens]\n",
    "\n",
    "        filtered_sentence = \" \".join(stripped).strip()\n",
    "        cleaned_text.append(filtered_sentence)\n",
    "    df['text'] = np.array(cleaned_text)\n",
    "    return df\n",
    "\n",
    "def remove_null(df):\n",
    "    if df['text'].isnull().sum() > 0:\n",
    "        df.dropna(inplace = True)\n",
    "    return df\n",
    "\n",
    "def detect_text(path):\n",
    "    \"\"\"Detects text in the file.\"\"\"\n",
    "    \n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    " \n",
    "    text_list = []\n",
    "\n",
    "    for text in texts:\n",
    "        text_list.append('\\n\"{}\"'.format(text.description))\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))\n",
    "    if text_list is None:\n",
    "        print(\"No Text Detected\")\n",
    "    \n",
    "    return text_list\n",
    "\n",
    "\n",
    "def removeStop(temp_df,stopwords = stop):\n",
    "    temp_df['text'] = temp_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "def cleanDataframeEnglish(df,column_name):\n",
    "  cleanedDf = pd.DataFrame(columns=['words'])\n",
    "  for index, row in df.iterrows():\n",
    "      word = row[column_name]\n",
    "      if word.isalnum() and not word.isspace() and word.isascii():\n",
    "        new_row = pd.DataFrame.from_records([{'words':word}])\n",
    "        # print(\"New Row\",new_row)\n",
    "        cleanedDf = pd.concat([cleanedDf,new_row],ignore_index=True)\n",
    "        # print(\"Iteration\",cleanedDf)\n",
    "\n",
    "  return cleanedDf\n",
    "\n",
    "def executeText(path):\n",
    "    image_text = detect_text(path)\n",
    "    if len(image_text) ==0:\n",
    "        returnDict = {'Word List': []}\n",
    "        return returnDict\n",
    "    temp_df = pd.DataFrame(columns=['text'])\n",
    "    temp_df['text'] = image_text[0].replace(\"\\n\",\" \").split()\n",
    "    temp_df = remove_punctuations(temp_df)\n",
    "    temp_df = lower_case(temp_df)\n",
    "    temp_df = remove_null(temp_df)\n",
    "    temp_df['text'] = temp_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    new_df = cleanDataframeEnglish(temp_df, 'text')   \n",
    "    word_list = new_df.values.flatten().tolist()\n",
    "    returnDict = {'Word List': word_list}\n",
    "\n",
    "    return returnDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = executeText(\"../images-115-max-keys-400/images/Ace-MR_Tablet/Ace-MR_Tablet1_gaussian_noise.jpg\")\n",
    "word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def color_moments(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    channels = cv2.split(img)\n",
    "\n",
    "    colour_features = []\n",
    "    for channel in channels:\n",
    "        moments = cv2.moments(channel)\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if i + j <= 2:\n",
    "                    colour_features.append(moments['m{}{}'.format(i, j)] / moments['m00'])\n",
    "\n",
    "    returnDict = {'Colour Features': colour_features}\n",
    "    return returnDict\n",
    "\n",
    "\n",
    "def texture_features(image_path):\n",
    "        # Convert image to grayscale\n",
    "\n",
    "        img = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Compute GLCM features\n",
    "        glcm = graycomatrix(gray, distances=[1], angles=[0], symmetric=True, normed=True)\n",
    "        contrast = graycoprops(glcm, 'contrast')\n",
    "        dissimilarity = graycoprops(glcm, 'dissimilarity')\n",
    "        homogeneity = graycoprops(glcm, 'homogeneity')\n",
    "        energy = graycoprops(glcm, 'energy')\n",
    "        correlation = graycoprops(glcm, 'correlation')\n",
    "\n",
    "        returnDict = {'Contrast': contrast.flatten()[0],\n",
    "                     'Dissimilarity': dissimilarity.flatten()[0], \n",
    "                     'Homogeneity': homogeneity.flatten()[0], \n",
    "                     'Energy':energy.flatten()[0], \n",
    "                     'Coorelation':correlation.flatten()[0]}\n",
    "        return returnDict\n",
    "\n",
    "def shape_features(image_path):\n",
    "    # Convert image to grayscale\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold the image to create a binary image\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Compute the contours of the binary image\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Compute the area, perimeter, and aspect ratio of each contour\n",
    "    areas = []\n",
    "    perimeters = []\n",
    "    aspect_ratios = []\n",
    "    centroid_xs = []\n",
    "    centroid_ys = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        aspect_ratio = w / h\n",
    "        centroid_x = x + w/2\n",
    "        centroid_y = y + h/2\n",
    "        areas.append(area)\n",
    "        perimeters.append(perimeter)\n",
    "        aspect_ratios.append(aspect_ratio)\n",
    "        centroid_xs.append(centroid_x)\n",
    "        centroid_ys.append(centroid_y)\n",
    "\n",
    "    # Compute the mean and standard deviation of the computed features\n",
    "    mean_area = np.mean(areas)\n",
    "    std_area = np.std(areas)\n",
    "    mean_perimeter = np.mean(perimeters)\n",
    "    std_perimeter = np.std(perimeters)\n",
    "    mean_aspect_ratio = np.mean(aspect_ratios)\n",
    "    std_aspect_ratio = np.std(aspect_ratios)\n",
    "    mean_centroid_x = np.mean(centroid_xs)\n",
    "    std_centroid_x = np.std(centroid_xs)\n",
    "    mean_centroid_y = np.mean(centroid_ys)\n",
    "    std_centroid_y = np.std(centroid_ys)\n",
    "\n",
    "    returnDict = {\n",
    "    'Mean Area': mean_area,\n",
    "    'Std Area': std_area,\n",
    "    'Mean Perimeter': mean_perimeter,\n",
    "    'Std Perimeter': std_perimeter,\n",
    "    'Mean Aspect Ratio': mean_aspect_ratio,\n",
    "    'Std Aspect Ratio': std_aspect_ratio,\n",
    "    'Mean Centroid X': mean_centroid_x,\n",
    "    'Std Centroid X': std_centroid_x,\n",
    "    'Mean Centroid Y': mean_centroid_y,\n",
    "    'Std Centroid Y': std_centroid_y\n",
    "    }   \n",
    "    # Return the computed features\n",
    "    return returnDict\n",
    "\n",
    "def pattern_features(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Compute the normalized histogram of the image\n",
    "    hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "    hist_norm = hist / np.sum(hist)\n",
    "\n",
    "    # Compute the entropy of the histogram\n",
    "    eps = np.finfo(float).eps\n",
    "    entropy = -np.sum(hist_norm * np.log2(hist_norm + eps))\n",
    "    entropylist = entropy.tolist()\n",
    "    # entropylist = [float(x) if isinstance(x, np.float32) else x for x in entropylist]\n",
    "    returnDict = {'Entropy': entropylist}\n",
    "\n",
    "    # Return the computed feature\n",
    "    return returnDict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texture = texture_features(\"Accept-SP_Tablet2 (1).jpg\")\n",
    "print(texture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeFeatures(image_path):\n",
    "    wordList = executeText(image_path)\n",
    "    colour_moments = color_moments(image_path)\n",
    "    texture = texture_features(image_path)\n",
    "    shape = shape_features(image_path)\n",
    "    pattern = pattern_features(image_path)\n",
    "\n",
    "    returnDict = {'Text' : wordList, 'Color Moments': colour_moments, 'Texture':texture,'Shape':shape, 'Pattern':pattern}\n",
    "\n",
    "    return returnDict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_EXTENSIONS = ('.jpg')\n",
    "\n",
    "def is_valid_image(filename):\n",
    "    \"\"\"Returns True if the file is a valid image file.\"\"\"\n",
    "    return os.path.splitext(filename)[1].lower() in VALID_EXTENSIONS\n",
    "\n",
    "def process_directory(dir_path):\n",
    "    \"\"\"Process directory and its contents.\"\"\"\n",
    "    image_path=[]\n",
    "    for filename in os.listdir(dir_path):\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        if os.path.isfile(file_path) and is_valid_image(filename):\n",
    "            # process image file here\n",
    "            image_path.append(file_path)\n",
    "        \n",
    "        elif os.path.isdir(file_path):\n",
    "            image_path.extend(process_directory(file_path))\n",
    "    return image_path\n",
    "\n",
    "# all_image_paths = []\n",
    "# # pass every directory path to process_directory function\n",
    "# for dirpath, dirnames, filenames in os.walk('../images-115-max-keys-400/images'):\n",
    "#     dir_name = os.path.basename(dirpath)\n",
    "#     image_path = process_directory(dirpath)\n",
    "#     all_image_paths.append(image_path)\n",
    "\n",
    "# for image_path in all_image_paths:\n",
    "#     for image_p in image_path:\n",
    "#         medicine_data = executeFeatures(image_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def toJson(image_path, directory,counter):\n",
    "    dir_name = directory\n",
    "    output_dir=\"metaanalysis\"\n",
    "    output_path1 = os.path.join(output_dir, dir_name)\n",
    "    if not os.path.exists(output_path1):\n",
    "        os.mkdir(output_path1)\n",
    "    output_name = f\"{dir_name}_{counter}.json\"\n",
    "    output_path = os.path.join(output_path1, output_name)\n",
    "    print(\"Outpath:\",output_path)\n",
    "    if os.path.exists(output_path):\n",
    "        output_name = f\"{dir_name}_{counter}.json\"\n",
    "        output_path = os.path.join(output_path1, output_name)\n",
    "        return 1\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(executeFeatures(image_path), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value for Acegrow_3D_Tablet: 49569.69868\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def find_value_by_name(name):\n",
    "    with open('../iqr_scores.csv', 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        next(csv_reader)  # Skip header row if present\n",
    "\n",
    "        for row in csv_reader:\n",
    "            if row[0] == name:\n",
    "                return row[1]\n",
    "\n",
    "    return None  # Return None if name not found\n",
    "\n",
    "# Usage example\n",
    "csv_file = '../iqr_scores.csv'  # Replace with your CSV file name/path\n",
    "name_to_search = 'Acegrow_3D_Tablet'  # Replace with the name you want to search for\n",
    "\n",
    "result = find_value_by_name(name_to_search)\n",
    "if result:\n",
    "    print(f\"Value for {name_to_search}: {result}\")\n",
    "else:\n",
    "    print(f\"No matching name found for {name_to_search}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dirpath, dirnames, filenames in os.walk('../images-115-max-keys-400/images'):\n",
    "    print(\"Dir:\",dirpath)\n",
    "    dir_name = os.path.basename(dirpath)\n",
    "    if dir_name == \"images\":\n",
    "        continue    \n",
    "    image_paths = process_directory(dirpath)\n",
    "    if not image_paths:\n",
    "        continue\n",
    "    counter = 0\n",
    "    for image_path in image_paths:\n",
    "        counter += 1\n",
    "        print(\"Image_path:\", image_path)\n",
    "        print(\"Dir name:\",dir_name)\n",
    "        toJson(image_path,dir_name, counter)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicine_data=executeFeatures(\"Accept-SP_Tablet2 (1).jpg\")\n",
    "medicine_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('Accept-SP_Tablet.json','w') as file:\n",
    "    json.dump(medicine_data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BTEP",
   "language": "python",
   "name": "btep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
