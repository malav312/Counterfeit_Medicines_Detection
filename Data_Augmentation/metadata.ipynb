{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "from google.cloud import vision\n",
    "import io\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from difflib import SequenceMatcher\n",
    "from textblob import TextBlob\n",
    "from fuzzywuzzy import process, fuzz\n",
    "import re\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pytesseract\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Stop Words\n",
    "stop = stopwords.words('english')\n",
    "with open('selected_words.txt', 'r') as f:\n",
    "    stop_words = [word.strip().replace('\"', '') for line in f.readlines() for word in line.split(',')]\n",
    "stop.extend(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detect and Process Text here\n",
    "def lower_case(df):\n",
    "    df['text'] = df['text'].apply(str.lower)\n",
    "    return df\n",
    "\n",
    "def remove_punctuations(df):\n",
    "    cleaned_text = []\n",
    "    for index in tqdm(range(df.shape[0])):\n",
    "        text = df['text'].iloc[index]\n",
    "\n",
    "        word_tokens = text.split()\n",
    "        \n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        stripped = [w.translate(table) for w in word_tokens]\n",
    "\n",
    "        filtered_sentence = \" \".join(stripped).strip()\n",
    "        cleaned_text.append(filtered_sentence)\n",
    "    df['text'] = np.array(cleaned_text)\n",
    "    return df\n",
    "\n",
    "def remove_null(df):\n",
    "    if df['text'].isnull().sum() > 0:\n",
    "        df.dropna(inplace = True)\n",
    "    return df\n",
    "\n",
    "def detect_text(path):\n",
    "    \"\"\"Detects text in the file.\"\"\"\n",
    "    \n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    " \n",
    "    text_list = []\n",
    "\n",
    "    for text in texts:\n",
    "        text_list.append('\\n\"{}\"'.format(text.description))\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))\n",
    "    \n",
    "    return text_list\n",
    "\n",
    "def removeStop(temp_df,stopwords = stop):\n",
    "    temp_df['text'] = temp_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "def cleanDataframeEnglish(df,column_name):\n",
    "  cleanedDf = pd.DataFrame(columns=['words'])\n",
    "  for index, row in df.iterrows():\n",
    "      word = row[column_name]\n",
    "      if word.isalnum() and not word.isspace() and word.isascii():\n",
    "        new_row = pd.DataFrame.from_records([{'words':word}])\n",
    "        # print(\"New Row\",new_row)\n",
    "        cleanedDf = pd.concat([cleanedDf,new_row],ignore_index=True)\n",
    "        # print(\"Iteration\",cleanedDf)\n",
    "\n",
    "  return cleanedDf\n",
    "\n",
    "def executeText(path):\n",
    "    image_text = detect_text(path)\n",
    "    temp_df = pd.DataFrame(columns=['text'])\n",
    "    temp_df['text'] = image_text[0].replace(\"\\n\",\" \").split()\n",
    "    temp_df = remove_punctuations(temp_df)\n",
    "    temp_df = lower_case(temp_df)\n",
    "    temp_df = remove_null(temp_df)\n",
    "    temp_df['text'] = temp_df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    new_df = cleanDataframeEnglish(temp_df, 'text')   \n",
    "    word_list = new_df.values.flatten().tolist()\n",
    "    returnDict = {'Word List': word_list}\n",
    "\n",
    "    return returnDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [00:00<00:00, 57587.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Word List': ['acceptsp', '20000']}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list = executeText(\"Accept-SP_Tablet2 (1).jpg\")\n",
    "word_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def color_moments(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    channels = cv2.split(img)\n",
    "\n",
    "    colour_features = []\n",
    "    for channel in channels:\n",
    "        moments = cv2.moments(channel)\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if i + j <= 2:\n",
    "                    colour_features.append(moments['m{}{}'.format(i, j)] / moments['m00'])\n",
    "\n",
    "    returnDict = {'Colour Features': colour_features}\n",
    "    return returnDict\n",
    "\n",
    "\n",
    "def texture_features(image_path):\n",
    "        # Convert image to grayscale\n",
    "\n",
    "        img = cv2.imread(image_path)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Compute GLCM features\n",
    "        glcm = graycomatrix(gray, distances=[1], angles=[0], symmetric=True, normed=True)\n",
    "        contrast = graycoprops(glcm, 'contrast')\n",
    "        dissimilarity = graycoprops(glcm, 'dissimilarity')\n",
    "        homogeneity = graycoprops(glcm, 'homogeneity')\n",
    "        energy = graycoprops(glcm, 'energy')\n",
    "        correlation = graycoprops(glcm, 'correlation')\n",
    "\n",
    "        returnDict = {'Contrast': contrast.flatten()[0],\n",
    "                     'Dissimilarity': dissimilarity.flatten()[0], \n",
    "                     'Homogeneity': homogeneity.flatten()[0], \n",
    "                     'Energy':energy.flatten()[0], \n",
    "                     'Coorelation':correlation.flatten()[0]}\n",
    "        return returnDict\n",
    "\n",
    "def shape_features(image_path):\n",
    "    # Convert image to grayscale\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Threshold the image to create a binary image\n",
    "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Compute the contours of the binary image\n",
    "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Compute the area, perimeter, and aspect ratio of each contour\n",
    "    areas = []\n",
    "    perimeters = []\n",
    "    aspect_ratios = []\n",
    "    centroid_xs = []\n",
    "    centroid_ys = []\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        aspect_ratio = w / h\n",
    "        centroid_x = x + w/2\n",
    "        centroid_y = y + h/2\n",
    "        areas.append(area)\n",
    "        perimeters.append(perimeter)\n",
    "        aspect_ratios.append(aspect_ratio)\n",
    "        centroid_xs.append(centroid_x)\n",
    "        centroid_ys.append(centroid_y)\n",
    "\n",
    "    # Compute the mean and standard deviation of the computed features\n",
    "    mean_area = np.mean(areas)\n",
    "    std_area = np.std(areas)\n",
    "    mean_perimeter = np.mean(perimeters)\n",
    "    std_perimeter = np.std(perimeters)\n",
    "    mean_aspect_ratio = np.mean(aspect_ratios)\n",
    "    std_aspect_ratio = np.std(aspect_ratios)\n",
    "    mean_centroid_x = np.mean(centroid_xs)\n",
    "    std_centroid_x = np.std(centroid_xs)\n",
    "    mean_centroid_y = np.mean(centroid_ys)\n",
    "    std_centroid_y = np.std(centroid_ys)\n",
    "\n",
    "    returnDict = {\n",
    "    'Mean Area': mean_area,\n",
    "    'Std Area': std_area,\n",
    "    'Mean Perimeter': mean_perimeter,\n",
    "    'Std Perimeter': std_perimeter,\n",
    "    'Mean Aspect Ratio': mean_aspect_ratio,\n",
    "    'Std Aspect Ratio': std_aspect_ratio,\n",
    "    'Mean Centroid X': mean_centroid_x,\n",
    "    'Std Centroid X': std_centroid_x,\n",
    "    'Mean Centroid Y': mean_centroid_y,\n",
    "    'Std Centroid Y': std_centroid_y\n",
    "    }   \n",
    "    # Return the computed features\n",
    "    return returnDict\n",
    "\n",
    "def pattern_features(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Compute the normalized histogram of the image\n",
    "    hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "    hist_norm = hist / np.sum(hist)\n",
    "\n",
    "    # Compute the entropy of the histogram\n",
    "    eps = np.finfo(float).eps\n",
    "    entropy = -np.sum(hist_norm * np.log2(hist_norm + eps))\n",
    "\n",
    "    returnDict = {'Entropy': entropy}\n",
    "\n",
    "    # Return the computed feature\n",
    "    return returnDict\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Contrast': 615.0416337025316, 'Dissimilarity': 9.433023470464136, 'Homogeneity': 0.5019732088818553, 'Energy': 0.13262236915429243, 'Coorelation': 0.839205042376685}\n"
     ]
    }
   ],
   "source": [
    "texture = texture_features(\"Accept-SP_Tablet2 (1).jpg\")\n",
    "print(texture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def executeFeatures(image_path):\n",
    "    wordList = executeText(image_path)\n",
    "    colour_moments = color_moments(image_path)\n",
    "    texture = texture_features(image_path)\n",
    "    shape = shape_features(image_path)\n",
    "    pattern = pattern_features(image_path)\n",
    "\n",
    "    returnDict = {'Text' : wordList, 'Color Moments': colour_moments, 'Texture':texture,'Shape':shape, 'Pattern':pattern}\n",
    "\n",
    "    return returnDict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 84/84 [00:00<00:00, 55431.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Text': {'Word List': ['acceptsp', '20000']},\n",
       " 'Color Moments': {'Colour Features': [1.0,\n",
       "   241.82269660016618,\n",
       "   77670.99784300446,\n",
       "   158.35815420887445,\n",
       "   38165.005853283306,\n",
       "   34035.683194369456,\n",
       "   1.0,\n",
       "   239.73730339309432,\n",
       "   76878.92557922703,\n",
       "   158.2292454910792,\n",
       "   37815.985687643224,\n",
       "   33985.5850936557,\n",
       "   1.0,\n",
       "   242.4240522970985,\n",
       "   78014.78238623713,\n",
       "   158.32791008105244,\n",
       "   38241.26631223746,\n",
       "   34017.41576882488]},\n",
       " 'Texture': {'Contrast': 615.0416337025316,\n",
       "  'Dissimilarity': 9.433023470464136,\n",
       "  'Homogeneity': 0.5019732088818553,\n",
       "  'Energy': 0.13262236915429243,\n",
       "  'Coorelation': 0.839205042376685},\n",
       " 'Shape': {'Mean Area': 151364.0,\n",
       "  'Std Area': 0.0,\n",
       "  'Mean Perimeter': 1590.0,\n",
       "  'Std Perimeter': 0.0,\n",
       "  'Mean Aspect Ratio': 0.6604166666666667,\n",
       "  'Std Aspect Ratio': 0.0,\n",
       "  'Mean Centroid X': 158.5,\n",
       "  'Std Centroid X': 0.0,\n",
       "  'Mean Centroid Y': 240.0,\n",
       "  'Std Centroid Y': 0.0},\n",
       " 'Pattern': {'Entropy': 5.4311476}}"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "executeFeatures(\"Accept-SP_Tablet2 (1).jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BTEP",
   "language": "python",
   "name": "btep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
